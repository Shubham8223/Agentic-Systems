{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from langmem import Memory, MemoryQuery\n",
        "from langmem.retrievers import SemanticRetriever, TimeRetriever\n",
        "from langmem.retrievers.combined_retriever import CombinedRetriever\n",
        "from langmem.stores import ChromaMemoryStore\n",
        "from langmem.memory_type import MemoryType\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class AgentState:\n",
        "    def __init__(\n",
        "        self,\n",
        "        messages: List[Dict] = None,\n",
        "        customer_id: str = None,\n",
        "        retrieved_memories: List[Dict] = None,\n",
        "        current_plan: Optional[Dict] = None,\n",
        "        next_steps: Optional[str] = None,\n",
        "    ):\n",
        "        self.messages = messages or []\n",
        "        self.customer_id = customer_id\n",
        "        self.retrieved_memories = retrieved_memories or []\n",
        "        self.current_plan = current_plan\n",
        "        self.next_steps = next_steps\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"AgentState(messages={len(self.messages)}, customer_id={self.customer_id})\"\n",
        "\n",
        "\n",
        "def initialize_memory_system(customer_id: str) -> Memory:\n",
        "    memory_store = ChromaMemoryStore(\n",
        "        collection_name=f\"customer_{customer_id}\",\n",
        "        embedding_function_name=\"openai\"\n",
        "    )\n",
        "\n",
        "    semantic_retriever = SemanticRetriever(\n",
        "        memory_store=memory_store,\n",
        "        similarity_threshold=0.7,\n",
        "        max_documents=5\n",
        "    )\n",
        "\n",
        "    time_retriever = TimeRetriever(\n",
        "        memory_store=memory_store,\n",
        "        recency_bias=0.2,\n",
        "        max_documents=3\n",
        "    )\n",
        "\n",
        "    combined_retriever = CombinedRetriever(\n",
        "        retrievers=[semantic_retriever, time_retriever],\n",
        "        weights=[0.7, 0.3]\n",
        "    )\n",
        "\n",
        "    memory = Memory(\n",
        "        memory_store=memory_store,\n",
        "        retriever=combined_retriever\n",
        "    )\n",
        "\n",
        "    return memory\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_customer_details(customer_id: str) -> Dict:\n",
        "    \"\"\"Retrieve customer profile and account information from the CRM database.\"\"\"\n",
        "    customer_data = {\n",
        "        \"CUS-1001\": {\n",
        "            \"name\": \"Jordan Smith\",\n",
        "            \"account_type\": \"Premium\",\n",
        "            \"signup_date\": \"2021-05-12\",\n",
        "            \"billing_status\": \"Active\",\n",
        "            \"subscription\": \"Annual ($1,200/year)\"\n",
        "        },\n",
        "        \"CUS-1002\": {\n",
        "            \"name\": \"Taylor Rodriguez\",\n",
        "            \"account_type\": \"Professional\",\n",
        "            \"signup_date\": \"2022-08-03\",\n",
        "            \"billing_status\": \"Past Due\",\n",
        "            \"subscription\": \"Monthly ($129/month)\"\n",
        "        },\n",
        "        \"CUS-1003\": {\n",
        "            \"name\": \"Alex Johnson\",\n",
        "            \"account_type\": \"Basic\",\n",
        "            \"signup_date\": \"2023-11-18\",\n",
        "            \"billing_status\": \"Active\",\n",
        "            \"subscription\": \"Monthly ($49/month)\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return customer_data.get(customer_id, {\"error\": \"Customer not found\"})\n",
        "\n",
        "\n",
        "@tool\n",
        "def check_support_history(customer_id: str, query: str = None) -> List[Dict]:\n",
        "    \"\"\"Retrieve past support tickets for the customer.\"\"\"\n",
        "    support_history = {\n",
        "        \"CUS-1001\": [\n",
        "            {\n",
        "                \"date\": \"2023-12-05\",\n",
        "                \"issue\": \"API rate limit exceeded\",\n",
        "                \"resolution\": \"Upgraded to higher tier\",\n",
        "                \"agent\": \"Priya K.\"\n",
        "            },\n",
        "            {\n",
        "                \"date\": \"2024-02-18\",\n",
        "                \"issue\": \"Data export functionality\",\n",
        "                \"resolution\": \"Provided custom script solution\",\n",
        "                \"agent\": \"Marco T.\"\n",
        "            }\n",
        "        ],\n",
        "        \"CUS-1002\": [\n",
        "            {\n",
        "                \"date\": \"2024-01-10\",\n",
        "                \"issue\": \"Billing dispute\",\n",
        "                \"resolution\": \"Applied one-time credit\",\n",
        "                \"agent\": \"Jamal R.\"\n",
        "            },\n",
        "            {\n",
        "                \"date\": \"2024-03-22\",\n",
        "                \"issue\": \"Account access issues\",\n",
        "                \"resolution\": \"Reset 2FA and passwords\",\n",
        "                \"agent\": \"Lisa M.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    customer_history = support_history.get(customer_id, [])\n",
        "\n",
        "    if query and customer_history:\n",
        "        filtered_history = []\n",
        "        for ticket in customer_history:\n",
        "            if query.lower() in ticket[\"issue\"].lower() or query.lower() in ticket[\"resolution\"].lower():\n",
        "                filtered_history.append(ticket)\n",
        "        return filtered_history\n",
        "\n",
        "    return customer_history\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_to_memory(customer_id: str, content: str, memory_type: str) -> Dict:\n",
        "    \"\"\"Save information to the customer's long-term memory.\"\"\"\n",
        "    memory = initialize_memory_system(customer_id)\n",
        "\n",
        "    if memory_type.lower() == \"interaction\":\n",
        "        mem_type = MemoryType.INTERACTION\n",
        "    elif memory_type.lower() == \"preference\":\n",
        "        mem_type = MemoryType.PREFERENCE\n",
        "    elif memory_type.lower() == \"fact\":\n",
        "        mem_type = MemoryType.FACT\n",
        "    else:\n",
        "        mem_type = MemoryType.NOTE\n",
        "\n",
        "    memory_id = str(uuid.uuid4())\n",
        "    timestamp = datetime.now().isoformat()\n",
        "\n",
        "    memory.add(\n",
        "        memory_id=memory_id,\n",
        "        content=content,\n",
        "        memory_type=mem_type,\n",
        "        metadata={\n",
        "            \"timestamp\": timestamp,\n",
        "            \"customer_id\": customer_id\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"memory_id\": memory_id,\n",
        "        \"message\": f\"Saved to {memory_type} memory\"\n",
        "    }\n",
        "\n",
        "\n",
        "@tool\n",
        "def retrieve_from_memory(customer_id: str, query: str, limit: int = 5) -> List[Dict]:\n",
        "    \"\"\"Retrieve relevant memories for this customer based on the query.\"\"\"\n",
        "    memory = initialize_memory_system(customer_id)\n",
        "\n",
        "    memory_query = MemoryQuery(\n",
        "        query=query,\n",
        "        filters={\"customer_id\": customer_id},\n",
        "        limit=limit\n",
        "    )\n",
        "\n",
        "    memories = memory.retrieve(memory_query)\n",
        "\n",
        "    results = []\n",
        "    for mem in memories:\n",
        "        results.append({\n",
        "            \"content\": mem.content,\n",
        "            \"type\": mem.memory_type.value,\n",
        "            \"timestamp\": mem.metadata.get(\"timestamp\", \"unknown\"),\n",
        "            \"relevance\": mem.relevance_score if hasattr(mem, \"relevance_score\") else None\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "@tool\n",
        "def update_customer_preferences(customer_id: str, preferences: Dict) -> Dict:\n",
        "    \"\"\"Update customer preferences in the CRM and long-term memory.\"\"\"\n",
        "    preferences_text = \", \".join([f\"{key}: {value}\" for key, value in preferences.items()])\n",
        "    content = f\"Customer preferences updated: {preferences_text}\"\n",
        "\n",
        "    save_result = save_to_memory(\n",
        "        customer_id=customer_id,\n",
        "        content=content,\n",
        "        memory_type=\"preference\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Customer preferences updated\",\n",
        "        \"memory_id\": save_result.get(\"memory_id\")\n",
        "    }\n",
        "\n",
        "\n",
        "tools = [\n",
        "    get_customer_details,\n",
        "    check_support_history,\n",
        "    save_to_memory,\n",
        "    retrieve_from_memory,\n",
        "    update_customer_preferences\n",
        "]\n",
        "\n",
        "\n",
        "# Node functions for our graph\n",
        "def identify_customer(state: AgentState) -> AgentState:\n",
        "    \"\"\"Extract or confirm customer ID from conversation.\"\"\"\n",
        "    messages = state.messages\n",
        "\n",
        "    if state.customer_id:\n",
        "        return state\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are an expert at identifying customer IDs in conversations.\n",
        "        Customer IDs follow the format CUS-XXXX where XXXX is a 4-digit number.\n",
        "        Extract the customer ID if present. If not found, respond with \"UNKNOWN\".\n",
        "        Only respond with the ID or \"UNKNOWN\", nothing else.\"\"\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "    extraction_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    result = extraction_chain.invoke({\"messages\": messages})\n",
        "\n",
        "    if result and result != \"UNKNOWN\":\n",
        "        state.customer_id = result.strip()\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def retrieve_memories(state: AgentState) -> AgentState:\n",
        "    \"\"\"Retrieve relevant memories based on the current conversation.\"\"\"\n",
        "    if not state.customer_id:\n",
        "        return state\n",
        "\n",
        "    if not state.messages:\n",
        "        return state\n",
        "\n",
        "    latest_message = state.messages[-1][\"content\"] if state.messages else \"\"\n",
        "\n",
        "    memories = retrieve_from_memory(\n",
        "        customer_id=state.customer_id,\n",
        "        query=latest_message\n",
        "    )\n",
        "\n",
        "    state.retrieved_memories = memories\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def get_customer_context(state: AgentState) -> AgentState:\n",
        "    \"\"\"Fetch current customer information from CRM.\"\"\"\n",
        "    if not state.customer_id:\n",
        "        return state\n",
        "\n",
        "    customer_details = get_customer_details(state.customer_id)\n",
        "\n",
        "    state.current_plan = customer_details\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def generate_response(state: AgentState) -> AgentState:\n",
        "    \"\"\"Generate a response using the LLM with memory context.\"\"\"\n",
        "\n",
        "    memory_context = \"No previous customer memories available.\"\n",
        "    if state.retrieved_memories:\n",
        "        memory_entries = []\n",
        "        for i, memory in enumerate(state.retrieved_memories):\n",
        "            memory_entries.append(\n",
        "                f\"{i+1}. [{memory['type']}] {memory['content']} ({memory['timestamp']})\"\n",
        "            )\n",
        "        memory_context = \"\\n\".join(memory_entries)\n",
        "\n",
        "    customer_info = \"Customer information unavailable.\"\n",
        "    if state.current_plan:\n",
        "        customer_info = \"\\n\".join([f\"{k}: {v}\" for k, v in state.current_plan.items()])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a helpful customer support agent with access to the customer's history.\n",
        "        Use the provided memories and customer information to give personalized support.\n",
        "        Be conversational, empathetic, and helpful. Address the customer by name when possible.\n",
        "\n",
        "        CUSTOMER INFORMATION:\n",
        "        {customer_info}\n",
        "\n",
        "        RELEVANT CUSTOMER MEMORIES:\n",
        "        {memory_context}\n",
        "\n",
        "        Guidelines:\n",
        "        - Reference past interactions naturally when relevant\n",
        "        - Remember customer preferences and adapt accordingly\n",
        "        - Be solution-oriented and proactive\n",
        "        - If you learn new customer preferences, needs, or important facts, make note of these\"\"\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0.7, model=\"gpt-4\")\n",
        "    response_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    response = response_chain.invoke({\n",
        "        \"messages\": state.messages,\n",
        "        \"memory_context\": memory_context,\n",
        "        \"customer_info\": customer_info\n",
        "    })\n",
        "\n",
        "    state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def summarize_interaction(state: AgentState) -> AgentState:\n",
        "    \"\"\"Summarize the interaction and save to memory.\"\"\"\n",
        "    if not state.customer_id or not state.messages:\n",
        "        return state\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"Summarize this customer interaction for future reference.\n",
        "        Focus on:\n",
        "        1. Key points discussed\n",
        "        2. Customer needs or issues\n",
        "        3. Solutions provided or actions taken\n",
        "        4. Any preferences or important facts learned\n",
        "\n",
        "        Keep it concise (1-2 paragraphs) but include all relevant information.\"\"\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "    summary_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    summary = summary_chain.invoke({\"messages\": state.messages})\n",
        "\n",
        "    save_to_memory(\n",
        "        customer_id=state.customer_id,\n",
        "        content=summary,\n",
        "        memory_type=\"interaction\"\n",
        "    )\n",
        "\n",
        "    extract_preferences_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"Extract any customer preferences mentioned in this conversation.\n",
        "        Return as a very brief comma-separated list of preferences in format \"key: value\".\n",
        "        If no preferences were mentioned, respond with \"none\".\"\"\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "\n",
        "    preferences_chain = extract_preferences_prompt | llm | StrOutputParser()\n",
        "    preferences = preferences_chain.invoke({\"messages\": state.messages})\n",
        "\n",
        "    if preferences and preferences.lower() != \"none\":\n",
        "        pref_dict = {}\n",
        "        for pref in preferences.split(\",\"):\n",
        "            if \":\" in pref:\n",
        "                key, value = pref.split(\":\", 1)\n",
        "                pref_dict[key.strip()] = value.strip()\n",
        "\n",
        "        if pref_dict:\n",
        "            update_customer_preferences(state.customer_id, pref_dict)\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def determine_next_action(state: AgentState) -> str:\n",
        "    \"\"\"Determine if the conversation should end or continue.\"\"\"\n",
        "    if not state.messages:\n",
        "        return \"identify_customer\"\n",
        "\n",
        "    last_message = state.messages[-1][\"content\"].lower() if state.messages[-1][\"role\"] == \"human\" else \"\"\n",
        "\n",
        "    end_signals = [\"goodbye\", \"thank you\", \"thanks for your help\", \"bye\", \"end\"]\n",
        "\n",
        "    if any(signal in last_message for signal in end_signals):\n",
        "        return END\n",
        "\n",
        "    return \"generate_response\" the conversation should end or continue\n",
        "    if not state.messages:\n",
        "        return \"identify_customer\"\n",
        "\n",
        "    # Get the last message\n",
        "    last_message = state.messages[-1][\"content\"].lower() if state.messages[-1][\"role\"] == \"human\" else \"\"\n",
        "\n",
        "    # Check for conversation ending signals\n",
        "    end_signals = [\"goodbye\", \"thank you\", \"thanks for your help\", \"bye\", \"end\"]\n",
        "\n",
        "    if any(signal in last_message for signal in end_signals):\n",
        "        return END\n",
        "\n",
        "    return \"generate_response\"\n",
        "\n",
        "\n",
        "# Create the graph\n",
        "def build_crm_agent():\n",
        "    \"\"\"Build and return the agent graph.\"\"\"\n",
        "    # Define our workflow\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"identify_customer\", identify_customer)\n",
        "    workflow.add_node(\"retrieve_memories\", retrieve_memories)\n",
        "    workflow.add_node(\"get_customer_context\", get_customer_context)\n",
        "    workflow.add_node(\"generate_response\", generate_response)\n",
        "    workflow.add_node(\"summarize_interaction\", summarize_interaction)\n",
        "\n",
        "    # Define the edges\n",
        "    workflow.add_edge(\"identify_customer\", \"retrieve_memories\")\n",
        "    workflow.add_edge(\"retrieve_memories\", \"get_customer_context\")\n",
        "    workflow.add_edge(\"get_customer_context\", \"generate_response\")\n",
        "    workflow.add_edge(\"generate_response\", \"summarize_interaction\")\n",
        "    workflow.add_edge(\"summarize_interaction\", \"determine_next_action\")\n",
        "\n",
        "    # Add conditional edge\n",
        "    workflow.add_conditional_edges(\n",
        "        \"determine_next_action\",\n",
        "        determine_next_action,\n",
        "        {\n",
        "            \"identify_customer\": \"identify_customer\",\n",
        "            \"generate_response\": \"retrieve_memories\",\n",
        "            END: END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"identify_customer\")\n",
        "\n",
        "    # Compile the graph\n",
        "    return workflow.compile()\n",
        "\n",
        "\n",
        "# Example of running the agent with checkpointing\n",
        "def run_agent_example():\n",
        "    \"\"\"Run the agent with a sample conversation.\"\"\"\n",
        "    # Build the agent\n",
        "    agent = build_crm_agent()\n",
        "\n",
        "    # Create a checkpointer (for persistence across sessions)\n",
        "    checkpointer = SqliteSaver(\":memory:\")\n",
        "\n",
        "    # Create a conversation thread\n",
        "    config = {\"configurable\": {\"thread_id\": \"thread_123\"}}\n",
        "\n",
        "    # First message\n",
        "    input_message = {\"messages\": [{\"role\": \"human\", \"content\": \"Hi, this is Jordan Smith. I'm customer CUS-1001. I'm having trouble with API rate limits again.\"}]}\n",
        "    result = agent.invoke(input_message, config)\n",
        "\n",
        "    # Show the result\n",
        "    print(f\"Customer ID: {result.customer_id}\")\n",
        "    print(f\"Agent response: {result.messages[-1]['content']}\")\n",
        "\n",
        "    # Second message\n",
        "    input_message = {\"messages\": result.messages + [{\"role\": \"human\", \"content\": \"Can you remind me what solution we found last time this happened?\"}]}\n",
        "    result = agent.invoke(input_message, config)\n",
        "\n",
        "    # Show the result\n",
        "    print(f\"Agent response: {result.messages[-1]['content']}\")\n",
        "\n",
        "    # Third message and wrap-up\n",
        "    input_message = {\"messages\": result.messages + [{\"role\": \"human\", \"content\": \"Great, thanks for your help today!\"}]}\n",
        "    result = agent.invoke(input_message, config)\n",
        "\n",
        "    # Show the final result\n",
        "    print(f\"Agent response: {result.messages[-1]['content']}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# If running as a script\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent_example()"
      ],
      "metadata": {
        "id": "GJIKOySiiU06"
      },
      "id": "GJIKOySiiU06",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}